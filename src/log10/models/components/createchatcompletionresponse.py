"""Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT."""

from __future__ import annotations
import dataclasses
from .chatcompletionresponsemessage import ChatCompletionResponseMessage
from .chatcompletiontokenlogprob import ChatCompletionTokenLogprob
from .completionusage import CompletionUsage
from dataclasses_json import Undefined, dataclass_json
from enum import Enum
from log10 import utils
from typing import Any, List, Optional


class FinishReason(str, Enum):
    r"""The reason the model stopped generating tokens. This will be `stop` if the model hit a natural stop point or a provided stop sequence,
    `length` if the maximum number of tokens specified in the request was reached,
    `content_filter` if content was omitted due to a flag from our content filters,
    `tool_calls` if the model called a tool, or `function_call` (deprecated) if the model called a function.
    """
    STOP = 'stop'
    LENGTH = 'length'
    TOOL_CALLS = 'tool_calls'
    CONTENT_FILTER = 'content_filter'
    FUNCTION_CALL = 'function_call'


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class Logprobs:
    r"""Log probability information for the choice."""
    content: Optional[List[ChatCompletionTokenLogprob]] = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('content') }})
    r"""A list of message content tokens with log probability information."""
    



@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class Choices:
    finish_reason: FinishReason = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('finish_reason') }})
    r"""The reason the model stopped generating tokens. This will be `stop` if the model hit a natural stop point or a provided stop sequence,
    `length` if the maximum number of tokens specified in the request was reached,
    `content_filter` if content was omitted due to a flag from our content filters,
    `tool_calls` if the model called a tool, or `function_call` (deprecated) if the model called a function.
    """
    index: int = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('index') }})
    r"""The index of the choice in the list of choices."""
    message: ChatCompletionResponseMessage = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('message') }})
    r"""A chat completion message generated by the model."""
    logprobs: Optional[Logprobs] = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('logprobs') }})
    r"""Log probability information for the choice."""
    



class Object(str, Enum):
    r"""The object type, which is always `chat.completion`."""
    CHAT_COMPLETION = 'chat.completion'


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class CreateChatCompletionResponse:
    r"""Represents a chat completion response returned by model, based on the provided input."""
    id: str = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('id') }})
    r"""A unique identifier for the chat completion."""
    choices: List[Choices] = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('choices') }})
    r"""A list of chat completion choices. Can be more than one if `n` is greater than 1."""
    created: int = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('created') }})
    r"""The Unix timestamp (in seconds) of when the chat completion was created."""
    model: Optional[Any] = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('model') }})
    r"""The ID of the [Model](/docs/api-reference/models) to be used to execute this run. If a value is provided here, it will override the model associated with the assistant. If not, the model associated with the assistant will be used."""
    object: Object = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('object') }})
    r"""The object type, which is always `chat.completion`."""
    system_fingerprint: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('system_fingerprint'), 'exclude': lambda f: f is None }})
    r"""This fingerprint represents the backend configuration that the model runs with.

    Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism.
    """
    usage: Optional[CompletionUsage] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('usage'), 'exclude': lambda f: f is None }})
    r"""Usage statistics for the completion request."""
    

